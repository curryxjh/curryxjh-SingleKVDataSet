# 从零实现一个单体的KV存储

常见的`KV`存储是`Redis`，但是`Redis`仍然是一种基于内存的数据库，虽然有一些持久化的技术(`AOF`和`RDB`)，但是本质上还是面向内存的，数据的持久性不能完全得到保障。



## bitcask

`bitcask`存储模型最初是由一个做分布式存储系统的公司`Riak`提出来的

他们想打造一个全新的存储引擎，在最理想的条件下，满足以下需求：

1. 读写低延迟
2. 高吞吐，特别是对大量的随机写入
3. 能够处理超过内存容量的数据
4. 崩溃恢复友好，能够保障快速恢复，尽量不丢失数据
5. 简单的备份和恢复策略
6. 相对简单、易懂的代码结构和数据存储格式
7. 在大数据量下，性能有保障
8. 能够有自由的授权使用在`Riak`的系统中

现有的存储引擎无法满足上述条件，于是`Riak`团队重新设计了一个简单高校的存储引擎`bitcask`



一个`bitcask`实例就是系统上的一个目录，并且限制同一时间只能有一个进程打开这个目录。目录中有多个文件，同一时刻只有一个活跃的文件用于写入新数据。如下图所示：

<img src="E:\KV\SingleKV\painting\bitcask.png" style="zoom: 80%;" />

当活跃文件写到满足一个阈值之后，就会被关闭，成为旧的数据文件，并且打开一个新的文件用于写入。所以这个目录中就是一个活跃文件和多个旧的数据文件的集合。

当前活跃文件的写入是追加的，这意味着可以利用顺序IO，不会有多余的磁盘寻址，减少了磁盘寻道时间，最大限度保证了吞吐。



写入到文件的数据，具有固定的格式，大致有这些字段：如下图

- `crc`：数据校验，防止数据被破坏、篡改等
- `timestamp`：写入数据的时间戳
- `ksz`：`key size`，`key`的大小
- `value_sz`：`value size`，`value`的大小
- `key`：用户实际存储的`key`
- `value`：用户实际存储的`value`

![](E:\KV\SingleKV\painting\数据格式.png)

每次写入都是追加到活跃的文件中，删除操作实际上也是一次追加写入操作，只不过写入的是一个特殊的墓碑值，用于标记一条记录的删除，也就是说不会实际的去原地删除某条数据。

当下一次`merge`的时候才会将这种无效的数据清除。

所以一个文件中的数据，实际上就是多个相同格式的数据集合的排列：如下图所示

![](E:\KV\SingleKV\painting\单个文件数据.png)

在追加写入磁盘文件完成后，然后更新内存中的数据结构，叫做`keydir`，实际上就是全部`key`的一个集合，存储的是key到一条磁盘文件的数据的位置。

此处论文中说使用哈希表来存储所有`key`的集合，但是实际上这里的选择比较灵活，选用任意内存中的数据结构都是可以的，可以根据自己的需求设计。



例如哈希表，可以更高效的获取数据，但是无法遍历数据，如果想要遍历数据，可以选择B树、跳表等天然支持排序的数据结构。

![](E:\KV\SingleKV\painting\内存key集合.png)

- file_id：表示数据存储到了哪一个文件中
- `value_pos`：表示数据存储在文件哪一个位置
- `value_sz`：`value size`
- `timestamp`：时间戳

`keydir`一定会存储一条数据在磁盘中的最新位置，旧的数据仍然存在，等待`merge`的时候被清理。



所以读取数据就会变得非常的简单，首先根据`key`从内存中找到对应的记录，这个记录存储的是数据在磁盘的位置，然后根据这个位置，找到磁盘对应的数据文件，以及文件中具体的偏移，这样就能够获取到完整的数据了。

查找流程如下：

<img src="E:\KV\SingleKV\painting\查找数据的流程.png"  />



由于旧的数据实际上一直存于磁盘文件中，因为我们并没有将旧的数据删除，而是新追加一条标识其被删除的记录，随着`bitsack`存储的数据越来越多，旧的数据也可能会越来越多，论文中提出了一个`merge`的过程来清理所有无效数据。



`merge`会遍历所有不可变的旧数据文件，将所有有效的数据重新写到新的数据文件中，并且将旧的数据文件删除。



`merge`完成后，还会为每个数据文件生成一个`hint`文件，`hint`文件可以看作是全部数据的索引，它和数据文件唯一的区别是，它不会存储实际的`value`。

<img src="E:\KV\SingleKV\painting\Merge.png" style="zoom: 80%;" />

`hint file`的作用是在`bitsack`启动的时候，直接加载`hint file`中的数据，快速构建索引，而不用去全部加载数据文件，换句话说，其实就是在启动的时候，加载更少的数据，因为`hint file`文件不存储`value`，它的容量会比数据文件更少。

`bitsack`一些面向用户的`API`操作接口：

```cpp
// 打开一个bitsack数据库实例，使用传入的目录路径
// 需要保证进程对该目录具有可读可写的权限
bitsack::Open(Directory Name);

// 通过Key获取存储的Value
bitsack::Get(Key);

// 存储Key和Value
bitsack::Put(Key, Value);

// 删除一个Key
bitsack::Delete(Key);

// 获取全部的Key
bitsack::list_keys();

// 遍历所有数据，执行函数Fun
bitsack::Fold(FUN);

// 执行merge，清理无效数据
bitsack::Merge(Directory Name);

// 刷盘，将所有缓冲区的写入持久化到磁盘中
bitsack::Sync();

// 关闭数据库
bitsack::Close();
```





**项目整体遵循`bitsack`的内存和磁盘设计，仅在一些细节中略有不同。因此总体分为以下两个部分：**

1. **内存中的数据如何存放**
2. **磁盘中的数据如何组织**

## 内存设计

在内存中，我们需要一种支持高效插入、读取、删除数据的数据结构，并且如果需要对数据高效遍历的话，我们最好选择一种天然支持有序的数据结构。

所以常见的选择有`B-Tree`、跳表、红黑树。

此处我们的实现，使用`B-Tree`，我们此处先使用`Google Repo`下开源的一`个B-Tree`库：[BTree implementation for Go](https://github.com/google/btree)

此外内存中中的数据结构设计还需要注意，可以根据自己的需求去设计。因此我们可以提供一个抽象接口，可以接入不同的数据结构，这样可以在设计上更加灵活，只需要实现我们抽象接口中的方法即可。



## 磁盘设计

我们将标准文件操作`API`例如`read`、`write`、`close`等方法进行简单封装，然后数据在磁盘上的读写可以使用这些标准的文件`API`。在项目中我们加入一个`fio`目录，专门存放关于文件`IO`操作的相关代码。

当前阶段只支持标准的系统文件`IO`，但是如果后面有其他的`IO`类型，例如`MMap`内存映射，或者自己写一层文件`IO`系统，都可以进行接入。

因此我们需要定义一个`IOManager`接口，将`IO`操作的接口进行抽象，方便接入不同的`IO`类型。



此外针对数据文件的操作，例如新增、删除数据文件，从文件中读取记录，可以增加一个目录`data`来存放，表示数据文件、数据项等内容。

内存和磁盘都设计完成了，基于`bitsack KV`存储引擎的结构如下图：

![](E:\KV\SingleKV\painting\架构.png)



## 数据读写

### 写数据流程

共分为两个步骤：

1. 先写磁盘文件
2. 再更新内存索引

首先先将封装到一个结构体，可以命名`LogRecord`，表示追加写到数据数据文件的日志记录。



`LogRecord`仅有三个字段：分别为`Key`、`Value`、`Type`，表示用户写入的`K/V`数据，以及标识数据类型的字段。因为在删除数据的时候，需要一个墓碑值，所以可以用`Type`来表示。

```go
// LogRecord 写入到数据文件的记录
// 叫日志的原因：因为数据文件中的数据写入方式是追加写入的，类似日志的格式
type LogRecord struct {
	Key   []byte
	Value []byte
	Type  LogRecordType
}
```

`LogRecord`构造好之后，需要增加一个追加写入到数据文件的方法`appendLogRecord`，这个方法在删除数据时也会使用到。

写入数据流程如下：

![](E:\KV\SingleKV\painting\写数据流程.png)

### 读数据流程

相较于写流程，读数据流程会更加简单。

首先根据用户传入的`Key`去内存索引数据结构中查找数据，如果未找到，则说明对应的`Key`不存在，直接返回一个不存在的错误即可。

如果找到了，则取出对应信息，这个位置信息即为`LogRecordPos`

根据文件信息中的文件`Id`，找到对应的数据文件，这里需要先判断是不是活跃文件，如果是的话则直接使用，否则就去旧的数据文件中寻找。

如果文件`Id`不存在则直接返回数据不存在的异常。

最后再根据`offset`从数据文件中读取数据。

流程如下图：

![](E:\KV\SingleKV\painting\读取数据流程.png)



## 数据库启动流程

启动的流程主要有两个步骤：

1. 加载数据目录中的文件，打开其文件描述符
2. 遍历数据文件内容，构建内存索引

当打开`bitsack`引擎时，用户会传递多个配置项，可以将配置项放到`Options`结构体中，根据需求增加

```go
type Options struct {
	DirPath      string // 数据库数据目录
	DataFileSize int64  // 数据文件大小
	SyncWrites   bool   // 每次写入之后是否需要执行一次安全的持久化
}
```

需要对配置项进行校验，避免用户传入了无效的配置项，从而发生破坏数据库的行为。



校验完成后，根据用户传入的数据目录，查看该目录是否存在，如果不存在的话，则说明第一次在这个目录启动`bitsack`实例，需要先创建目录。

我们需要定义一个`bitsack`实例的结构体，里面存放索引、数据文件等内容，在启动的时候，初始化该结构体。

将该结构体定义为`DB`，大致结构如下：

```go
type DB struct {
	options    Options // 数据库配置项
	mu         *sync.RWMutex
	activeFile *data.DataFile            // 当前活跃数据文件，用于写入
	oldFiles   map[uint32]*data.DataFile // 旧的数据文件，用于读取
	index      index.Indexer             //内存索引
}
```

### 加载数据文件

首先需要加载数据文件，我们将定义一个`loadDataFiles`，将加载操作全部写到这个方法里。

1. 打开用户传递的数据目录，如果判断这个目录下没有文件的话，表示是一个空的数据库，则直接返回
2. 加载这个目录下的数据文件，我们可以约定一个`bitcask`存储引擎的数据文件的拓展名，然后加载数据文件的时候，可以直接加载拥有这个后缀名的文件。

我们将后缀名定义为：`.data`，表示是数据文件。

我们直接遍历查看这个目录下的文件，然后找出所有以`.data`结尾的文件，并且取出文件的`id`，文件`id`我们可以用文件名称来标识，当有很多个数据存在的时候，将这个`id`递增，作为数据文件的名称。

取出所有文件的`id`后，遍历的同时，构造对应的文件路径+文件名，再调用`DataFile`的方法，打开对应的文件。

需要注意，我们需要标识最大的`id`，因为最大的`id`所代表的数据文件就是当前活跃文件。



### 加载索引

有了数据文件之后，需要构建索引





## 数据删除流程

与写数据的流程相似，基于`bitsack`论文，删除数据其实也是向数据文件中追加一条记录，只是需要标记其类型是被删除的，也就是一个墓碑值。





## 数据文件逻辑



## 读取LogRecord

一条`LogRecord`记录：

![](E:\KV\SingleKV\painting\logRecord.png)

上图是一条`LogRecord`的结构

- 一部分是头部信息，存储了一些元数据，例如`CRC`校验值，`Type`类型，`Key`大小，`Value`大小
- 第二个部分是用户实际的`Key/Value`部分

此处需要注意一个点：我们存储了用户实际的`Key/Value`之外，为什么还要存储它对应的大小`Key Size、Value Size`呢？

这是因为用户传递过来的`Key/Value`长度是不确定的，这样我们在读取对应数据的时候，并不知道应该读取多少个字节，所以就需要加上一个对应的大小，我们先读取头部部分，这部分的长度是固定的，读取完成之后，我们就知道实际的大小了，然后再根据得到的大小，去读取用户实际存储的内容。

`Header`部分的数据中，`CRC`占4个字节，`Type`占1个字节，而`Key Size，Value Size`是变长的，所以在读取的时候，我们会读取最大字节数

为什么要设计为变长呢？主要是为了节省空间，如果`Key Size、Value Size`都是`uint32`类型的，如果不适用变长，则将固定占据4字节，但是有时候我们`Key`长度很小，例如只有`5`，其实只需要1个字节。



注意我们读取`LogRecord`的信息，获取的为二进制编码的，我们需要将其解压缩，得到具体的信息，目前主要包含上图的四个字段。

拿到`header`之后，如果判断`Key`和`Value`的长度都为0，则说明读取到了文件的末尾，直接返回一个`EOF`错误。

否则根据长度信息，判断其值是否大于0，如果是的话，则说明存在对应的`Key、Value`

我们就将读偏移量`Offset`加上`Key Size、Value Size`的总和，读出一个字节数组，这其中`Key/Value`数据，填充到`LogRecord`结构体中。

最后，需要根据读出的信息，获取到其对应的校验值`CRC`，判断`Header`中的`CRC`是否相等，只有完全相等，才说明这是一条完整的有效数据，否则说明数据可能被破坏了。





## Merge操作

清理磁盘上无效数据

按照编号大小依次读取数据文件，并且依次取出其中的每一条日志记录，然后跟内存中的索引进行比较，如果和内存索引对应的文件`id`和编译`offset`一致，说明这是有效的数据，然后直接调用`Put`接口重写这条数据即可(重新写入活跃文件)，一个文件中的数据重写完成后，直接删除即可。

但是这样会频繁调用`Put`接口，增加此方法的锁竞争。因为这个方法是暴露给外部调用者的。

并且假设数据写到一半，出现错误，此时新的数据文件中有新重写的数据，而旧的文件又不能删除掉。解决这个问题的方法可以是放到前面实现的事务中，当事务完成后，才可以删除文件，但是如果一个文件中数据量过大，提交事务的时候，会将数据批量缓存到内存中，这样会造成内存膨胀。

所以使用另外一种方法，我们使用一个临时文件夹，假设叫`Merge`在这个临时目录中新启动一个数据库实例，这个实例和正在运行的数据库实例不冲突，因为他们是不同的进程，将原来的目录中的数据文件逐一读取，并取出其中的日志记录，和内存索引进行比较，如果是有效的，将其重写到`Merge`这个数据目录中，避免和原来的目录竞争。

![](E:\KV\SingleKV\painting\Merge过程.png)

此时重写数据时，并不会影响到原来数据目录上的`bitcask`引擎实例，对用户的正常写数据降低了影响。

## 生成hint索引文件

`hint file`的作用是在`bitsack`启动的时候，直接加载`hint file`中的数据，快速构建索引，而不用去全部加载数据文件，换句话说，其实就是在启动的时候，加载更少的数据，因为`hint file`文件不存储`value`，它的容量会比数据文件更少。

在重写数据到`Merge`目录的时候，实际上依旧会得到一个位置索引信息，将这个索引信息和原始的`key`保存到一个新的`hint`文件即可，这个`hint`文件沿用数据文件的结构，采用日志追加的方式。

## 重新校验merge

`Merge`时还需要考虑一个问题，在`Merge`过程中发生了异常，例如进程退出，或者系统崩溃，导致`Merge`没有完成，应该如何处理这种问题。最简单直接的方法，可以在数据全部重写完成后，在磁盘上增加一个标识`Merge`完成的文件，当重启数据库的时候，我们查看其是否有对应的`Merge`目录，找到了这个目录之后，说明发生过`Merge`， 然后在这个目录中查找是否有`Merge`完成的文件，如果没有，则说明是一次无效操作，我们将此`Merge`目录删除。
